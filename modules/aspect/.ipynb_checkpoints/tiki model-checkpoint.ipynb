{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da0b2100",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:67: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.6.0 and strictly below 2.9.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.3.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  UserWarning,\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Conv1D,GRU\n",
    "from tensorflow.keras.layers import Bidirectional, GlobalMaxPool1D, Concatenate\n",
    "from tensorflow.keras.models import Model,load_model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow_addons as tfa\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c925714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2940, 50) (2940, 7)\n"
     ]
    }
   ],
   "source": [
    "max_len=50\n",
    "feat_vec=300\n",
    "with open (\"../../encode_data_shopee.txt\", \"r\") as f:\n",
    "    encode_data_shopee = json.loads(f.read())\n",
    "with open (\"../../output_shopee.txt\", \"r\") as f:\n",
    "    output_ori_shopee = np.array(json.loads(f.read()))\n",
    "    \n",
    "padded_doc_shopee=pad_sequences(encode_data_shopee,maxlen=max_len,padding=\"post\")\n",
    "\n",
    "\n",
    "with open (\"../../encode_data_tiki.txt\", \"r\") as f:\n",
    "    encode_data_tiki = json.loads(f.read())\n",
    "padded_doc_tiki=pad_sequences(encode_data_tiki,maxlen=max_len,padding=\"post\")\n",
    "with open (\"../../output_tiki.txt\", \"r\") as f:\n",
    "    output_ori_tiki = np.array(json.loads(f.read()))\n",
    "print(padded_doc_tiki.shape, output_ori_tiki.shape)\n",
    "X_train_tiki, X_test_tiki, y_train_ori_tiki, y_test_ori_tiki = train_test_split(padded_doc_tiki, output_ori_tiki, test_size=0.2, random_state=14)\n",
    "X_train_aug = np.concatenate((X_train_tiki, padded_doc_shopee))\n",
    "y_train_ori_aug = np.concatenate((y_train_ori_tiki, output_ori_shopee)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a66cb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "600a5060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(y_train_ori_tiki[:,0])\n",
    "# y_train_tiki = y_train_ori_tiki[:, [0, 4]]\n",
    "# y_test_tiki = y_test_ori_tiki[:, [0, 4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70a8efd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_tiki = np.delete(y_train_ori_tiki, 6, 1)\n",
    "y_test_tiki = np.delete(y_test_ori_tiki, 6, 1)\n",
    "y_train_aug = np.delete(y_train_ori_aug, 6, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9033fb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2352, 50)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tiki.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e481ba21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5237"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_trained = np.load('./weights/embedding_trained_mat.npy')\n",
    "lstm_trained = np.load('./weights/lstm_trained_mat.npy', allow_pickle=True)\n",
    "# len(lstm_trained)\n",
    "embed_mat = np.load('./weights/embedding_mat.npy')\n",
    "# len(embed_mat)\n",
    "len(embed_trained[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7abe181b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convo_trained = np.load('./weights/convo_trained_mat.npy', allow_pickle=True)\n",
    "# len(convo_trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "352704f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "f1 = tfa.metrics.F1Score(num_classes=6, average='macro', threshold=0.5)\n",
    "# rlp = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_f1_score',mode='max', patience=3, verbose=1, factor=0.4)\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_f1_score',mode='max', patience=10, verbose=1, restore_best_weights=True)\n",
    "filepath = ('./weights/best_student.hdf5')\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_f1_score', verbose=1, save_best_only=True,save_weights_only=True, mode='max')\n",
    "\n",
    "def get_model_distilled():\n",
    "    inp = Input(shape=(max_len,))\n",
    "    x = Embedding(len(embed_mat), feat_vec, weights=[embed_mat], input_length=max_len,trainable=True)(inp) \n",
    "\n",
    "#     embed_distill = Embedding(len(embed_trained[0]), feat_vec, weights=[embed_trained[0]], input_length=max_len,trainable=False)(inp) # trọng số của từ sẽ không được train lại\n",
    "#     embed_train = Embedding(len(embed_trained[0]), feat_vec, weights=[embed_mat], input_length=max_len,trainable=True)(inp)\n",
    "#     reduce_embed_train = Dense(270, activation=\"relu\")(embed_train)\n",
    "\n",
    "#     embed_concat = Concatenate(axis=-1)([0.9*embed_distill,0.1*embed_train])\n",
    "#     x = Dropout(0.4)(x)\n",
    "\n",
    "#     embed_combine = 0.9*embed_distill + 0.1*embed_train\n",
    "#     x = Dropout(0.4)(embed_combine)\n",
    "\n",
    "    lstm_distill = Bidirectional(LSTM(128, return_sequences=True))(x)\n",
    "#     reduce_lstm_distill = Dense(26, activation=\"relu\")(lstm_distill)\n",
    "    lstm_train = Bidirectional(LSTM(128, return_sequences=True))(x)\n",
    "    lstm_concat = Concatenate(axis=-1)([0.7*lstm_distill,0.3*lstm_train])\n",
    "#     lstm_combine = 0.5*lstm_distill+0.5*lstm_train\n",
    "#     x = Bidirectional(LSTM(128, return_sequences=True), trainable=True)(x)\n",
    "\n",
    "#     convo_distill = Conv1D(64,3,activation=\"relu\")(lstm_combine)    \n",
    "#     convo_train = Conv1D(64,3,activation=\"relu\")(lstm_combine)\n",
    "#     convo_concat = Concatenate(axis=-1)([0.2*convo_distill,0.8*convo_train])\n",
    "#     convo_combine = 0.3*convo_distill+0.7*convo_train\n",
    "    x = Conv1D(64,3,activation=\"relu\")(lstm_concat)\n",
    "    x = GlobalMaxPool1D()(x)\n",
    "#     x = Dropout(0.4)(x)\n",
    "\n",
    "    x = Dense(128, activation=\"relu\")(x)\n",
    "#     x = Dense(32, activation=\"relu\")(x)\n",
    "#     x = Dropout(0.4)(x)\n",
    "    x = Dense(6, activation=\"sigmoid\")(x)\n",
    "    model = Model(inputs=inp, outputs=x)\n",
    "    print(model.layers[3].name)\n",
    "    model.layers[3].trainable = False\n",
    "    #     model.layers[11].trainable = False\n",
    "#     print(model.layers[6].trainable)\n",
    "    print(model.summary())\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(lr=0.005), metrics= [f1])\n",
    "    return model\n",
    "def get_model_normal():\n",
    "    inp = Input(shape=(max_len,))\n",
    "    x = Embedding(len(embed_mat), feat_vec, weights=[embed_mat], input_length=max_len,trainable=True)(inp) # trọng số của từ sẽ không được train lại\n",
    "    x = Bidirectional(LSTM(128, return_sequences=True), trainable=True)(x)\n",
    "    x = Conv1D(64,3,activation=\"relu\")(x)\n",
    "\n",
    "#     convo_distill = Conv1D(64,3,activation=\"relu\")(x)\n",
    "#     convo_train = Conv1D(64,3,activation=\"relu\")(x)\n",
    "#     convo_concat = Concatenate(axis=-1)([0.2*convo_distill,0.8*convo_train])\n",
    "    x = GlobalMaxPool1D()(x)\n",
    "    x = Dense(128, activation=\"relu\")(x)\n",
    "#     x = Dense(32, activation=\"relu\")(x)\n",
    "#     x = Dropout(0.5)(x)\n",
    "    x = Dense(6, activation=\"sigmoid\")(x)\n",
    "    model = Model(inputs=inp, outputs=x)\n",
    "    print(model.summary())\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(lr=0.005), metrics= [f1])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6d7b5a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bidirectional_25\n",
      "Model: \"functional_25\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_13 (InputLayer)           [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_12 (Embedding)        (None, 50, 300)      1571100     input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_24 (Bidirectional (None, 50, 256)      439296      embedding_12[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_25 (Bidirectional (None, 50, 256)      439296      embedding_12[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_24 (TensorFlowO [(None, 50, 256)]    0           bidirectional_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_25 (TensorFlowO [(None, 50, 256)]    0           bidirectional_25[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 50, 512)      0           tf_op_layer_Mul_24[0][0]         \n",
      "                                                                 tf_op_layer_Mul_25[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 48, 64)       98368       concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_12 (Global (None, 64)           0           conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 128)          8320        global_max_pooling1d_12[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_25 (Dense)                (None, 6)            774         dense_24[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 2,557,154\n",
      "Trainable params: 2,117,858\n",
      "Non-trainable params: 439,296\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = get_model_distilled()\n",
    "# .fit(X_train_tiki, y_train_tiki, batch_size=8, epochs=15, validation_data=(X_test_tiki, y_test_tiki), callbacks=[checkpoint])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a6f2792f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[3].set_weights(lstm_trained)\n",
    "# model.layers[11].set_weights(convo_trained)\n",
    "# model.layers[3].set_weights(convo_trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a668ce81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.3794 - f1_score: 0.4111\n",
      "Epoch 00001: val_f1_score improved from -inf to 0.52765, saving model to ./weights\\best_student.hdf5\n",
      "37/37 [==============================] - 12s 325ms/step - loss: 0.3794 - f1_score: 0.4111 - val_loss: 0.2667 - val_f1_score: 0.5276\n",
      "Epoch 2/20\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.1971 - f1_score: 0.6685\n",
      "Epoch 00002: val_f1_score improved from 0.52765 to 0.68636, saving model to ./weights\\best_student.hdf5\n",
      "37/37 [==============================] - 11s 288ms/step - loss: 0.1971 - f1_score: 0.6685 - val_loss: 0.2189 - val_f1_score: 0.6864\n",
      "Epoch 3/20\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.1143 - f1_score: 0.8704\n",
      "Epoch 00003: val_f1_score improved from 0.68636 to 0.78982, saving model to ./weights\\best_student.hdf5\n",
      "37/37 [==============================] - 10s 282ms/step - loss: 0.1143 - f1_score: 0.8704 - val_loss: 0.2111 - val_f1_score: 0.7898\n",
      "Epoch 4/20\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0721 - f1_score: 0.9231\n",
      "Epoch 00004: val_f1_score did not improve from 0.78982\n",
      "37/37 [==============================] - 11s 291ms/step - loss: 0.0721 - f1_score: 0.9231 - val_loss: 0.2507 - val_f1_score: 0.7855\n",
      "Epoch 5/20\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0430 - f1_score: 0.9636\n",
      "Epoch 00005: val_f1_score improved from 0.78982 to 0.79200, saving model to ./weights\\best_student.hdf5\n",
      "37/37 [==============================] - 15s 395ms/step - loss: 0.0430 - f1_score: 0.9636 - val_loss: 0.2954 - val_f1_score: 0.7920\n",
      "Epoch 6/20\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0271 - f1_score: 0.9743\n",
      "Epoch 00006: val_f1_score did not improve from 0.79200\n",
      "37/37 [==============================] - 14s 381ms/step - loss: 0.0271 - f1_score: 0.9743 - val_loss: 0.3751 - val_f1_score: 0.7689\n",
      "Epoch 7/20\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0198 - f1_score: 0.9812\n",
      "Epoch 00007: val_f1_score did not improve from 0.79200\n",
      "37/37 [==============================] - 15s 407ms/step - loss: 0.0198 - f1_score: 0.9812 - val_loss: 0.3844 - val_f1_score: 0.7775\n",
      "Epoch 8/20\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0193 - f1_score: 0.9780\n",
      "Epoch 00008: val_f1_score did not improve from 0.79200\n",
      "37/37 [==============================] - 14s 387ms/step - loss: 0.0193 - f1_score: 0.9780 - val_loss: 0.4393 - val_f1_score: 0.7733\n",
      "Epoch 9/20\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0231 - f1_score: 0.9709\n",
      "Epoch 00009: val_f1_score did not improve from 0.79200\n",
      "37/37 [==============================] - 15s 393ms/step - loss: 0.0231 - f1_score: 0.9709 - val_loss: 0.4172 - val_f1_score: 0.7726\n",
      "Epoch 10/20\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0141 - f1_score: 0.9828\n",
      "Epoch 00010: val_f1_score did not improve from 0.79200\n",
      "37/37 [==============================] - 14s 385ms/step - loss: 0.0141 - f1_score: 0.9828 - val_loss: 0.4594 - val_f1_score: 0.7649\n",
      "Epoch 11/20\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0153 - f1_score: 0.9863\n",
      "Epoch 00011: val_f1_score did not improve from 0.79200\n",
      "37/37 [==============================] - 14s 388ms/step - loss: 0.0153 - f1_score: 0.9863 - val_loss: 0.5628 - val_f1_score: 0.7684\n",
      "Epoch 12/20\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0193 - f1_score: 0.9788\n",
      "Epoch 00012: val_f1_score did not improve from 0.79200\n",
      "37/37 [==============================] - 14s 386ms/step - loss: 0.0193 - f1_score: 0.9788 - val_loss: 0.5161 - val_f1_score: 0.7699\n",
      "Epoch 13/20\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0201 - f1_score: 0.9816\n",
      "Epoch 00013: val_f1_score did not improve from 0.79200\n",
      "37/37 [==============================] - 14s 382ms/step - loss: 0.0201 - f1_score: 0.9816 - val_loss: 0.4989 - val_f1_score: 0.7744\n",
      "Epoch 14/20\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0157 - f1_score: 0.9854\n",
      "Epoch 00014: val_f1_score did not improve from 0.79200\n",
      "37/37 [==============================] - 14s 381ms/step - loss: 0.0157 - f1_score: 0.9854 - val_loss: 0.5452 - val_f1_score: 0.7569\n",
      "Epoch 15/20\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0126 - f1_score: 0.9913\n",
      "Epoch 00015: val_f1_score did not improve from 0.79200\n",
      "Restoring model weights from the end of the best epoch.\n",
      "37/37 [==============================] - 14s 389ms/step - loss: 0.0126 - f1_score: 0.9913 - val_loss: 0.5622 - val_f1_score: 0.7747\n",
      "Epoch 00015: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24021a01c08>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_tiki, y_train_tiki, batch_size=64, epochs=20, validation_data=(X_test_tiki, y_test_tiki), callbacks=[checkpoint, es])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "458c32d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bidirectional_27\n",
      "Model: \"functional_27\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_14 (InputLayer)           [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_13 (Embedding)        (None, 50, 300)      1571100     input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_26 (Bidirectional (None, 50, 256)      439296      embedding_13[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_27 (Bidirectional (None, 50, 256)      439296      embedding_13[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_26 (TensorFlowO [(None, 50, 256)]    0           bidirectional_26[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_27 (TensorFlowO [(None, 50, 256)]    0           bidirectional_27[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 50, 512)      0           tf_op_layer_Mul_26[0][0]         \n",
      "                                                                 tf_op_layer_Mul_27[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 48, 64)       98368       concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_13 (Global (None, 64)           0           conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_26 (Dense)                (None, 128)          8320        global_max_pooling1d_13[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_27 (Dense)                (None, 6)            774         dense_26[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 2,557,154\n",
      "Trainable params: 2,117,858\n",
      "Non-trainable params: 439,296\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "new_model = get_model_distilled()\n",
    "new_model.load_weights('./weights/best_student.hdf5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "34b7b7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "def evaluate(X_test, y_test, model):    \n",
    "    y_pre = model.predict(X_test)\n",
    "    for thresh in np.arange(0.1,0.9,0.01):\n",
    "        print(\"threshold {0:2.2f} f1 score:{1:2.3f}\".format(thresh,metrics.f1_score(y_test,(y_pre>thresh).astype(int), average='macro')))\n",
    "    return y_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "53282798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.keras.engine.functional.Functional"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e9226d2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold 0.10 f1 score:0.769\n",
      "threshold 0.11 f1 score:0.773\n",
      "threshold 0.12 f1 score:0.771\n",
      "threshold 0.13 f1 score:0.774\n",
      "threshold 0.14 f1 score:0.778\n",
      "threshold 0.15 f1 score:0.776\n",
      "threshold 0.16 f1 score:0.775\n",
      "threshold 0.17 f1 score:0.775\n",
      "threshold 0.18 f1 score:0.772\n",
      "threshold 0.19 f1 score:0.777\n",
      "threshold 0.20 f1 score:0.782\n",
      "threshold 0.21 f1 score:0.781\n",
      "threshold 0.22 f1 score:0.782\n",
      "threshold 0.23 f1 score:0.784\n",
      "threshold 0.24 f1 score:0.784\n",
      "threshold 0.25 f1 score:0.788\n",
      "threshold 0.26 f1 score:0.787\n",
      "threshold 0.27 f1 score:0.787\n",
      "threshold 0.28 f1 score:0.784\n",
      "threshold 0.29 f1 score:0.784\n",
      "threshold 0.30 f1 score:0.785\n",
      "threshold 0.31 f1 score:0.786\n",
      "threshold 0.32 f1 score:0.783\n",
      "threshold 0.33 f1 score:0.785\n",
      "threshold 0.34 f1 score:0.784\n",
      "threshold 0.35 f1 score:0.786\n",
      "threshold 0.36 f1 score:0.786\n",
      "threshold 0.37 f1 score:0.786\n",
      "threshold 0.38 f1 score:0.787\n",
      "threshold 0.39 f1 score:0.787\n",
      "threshold 0.40 f1 score:0.785\n",
      "threshold 0.41 f1 score:0.786\n",
      "threshold 0.42 f1 score:0.787\n",
      "threshold 0.43 f1 score:0.788\n",
      "threshold 0.44 f1 score:0.789\n",
      "threshold 0.45 f1 score:0.789\n",
      "threshold 0.46 f1 score:0.789\n",
      "threshold 0.47 f1 score:0.792\n",
      "threshold 0.48 f1 score:0.793\n",
      "threshold 0.49 f1 score:0.791\n",
      "threshold 0.50 f1 score:0.792\n",
      "threshold 0.51 f1 score:0.792\n",
      "threshold 0.52 f1 score:0.792\n",
      "threshold 0.53 f1 score:0.793\n",
      "threshold 0.54 f1 score:0.792\n",
      "threshold 0.55 f1 score:0.791\n",
      "threshold 0.56 f1 score:0.791\n",
      "threshold 0.57 f1 score:0.792\n",
      "threshold 0.58 f1 score:0.791\n",
      "threshold 0.59 f1 score:0.793\n",
      "threshold 0.60 f1 score:0.794\n",
      "threshold 0.61 f1 score:0.787\n",
      "threshold 0.62 f1 score:0.787\n",
      "threshold 0.63 f1 score:0.787\n",
      "threshold 0.64 f1 score:0.784\n",
      "threshold 0.65 f1 score:0.783\n",
      "threshold 0.66 f1 score:0.784\n",
      "threshold 0.67 f1 score:0.782\n",
      "threshold 0.68 f1 score:0.784\n",
      "threshold 0.69 f1 score:0.786\n",
      "threshold 0.70 f1 score:0.786\n",
      "threshold 0.71 f1 score:0.786\n",
      "threshold 0.72 f1 score:0.786\n",
      "threshold 0.73 f1 score:0.787\n",
      "threshold 0.74 f1 score:0.786\n",
      "threshold 0.75 f1 score:0.786\n",
      "threshold 0.76 f1 score:0.786\n",
      "threshold 0.77 f1 score:0.786\n",
      "threshold 0.78 f1 score:0.785\n",
      "threshold 0.79 f1 score:0.788\n",
      "threshold 0.80 f1 score:0.789\n",
      "threshold 0.81 f1 score:0.782\n",
      "threshold 0.82 f1 score:0.782\n",
      "threshold 0.83 f1 score:0.779\n",
      "threshold 0.84 f1 score:0.777\n",
      "threshold 0.85 f1 score:0.775\n",
      "threshold 0.86 f1 score:0.778\n",
      "threshold 0.87 f1 score:0.770\n",
      "threshold 0.88 f1 score:0.766\n",
      "threshold 0.89 f1 score:0.760\n"
     ]
    }
   ],
   "source": [
    "y_pre=evaluate(X_test_tiki, y_test_tiki, new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5fa394b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p: [0.8995983935742972, 0.8925619834710744, 0.5806451612903226, 0.8106312292358804, 0.7009345794392523, 0.7924528301886793]\n",
      "r: [0.9655172413793104, 0.9, 0.75, 0.8531468531468531, 0.7009345794392523, 0.711864406779661]\n",
      "f1: [0.9313929313929314, 0.8962655601659751, 0.6545454545454547, 0.8313458262350937, 0.7009345794392523, 0.75]\n",
      "micro: (0.826946847960445, 0.8699609882964889, 0.8479087452471483)\n",
      "macro: (0.7768742694021654, 0.8339197347930831, 0.8028968703557414)\n"
     ]
    }
   ],
   "source": [
    "thresh=0.6\n",
    "\n",
    "\n",
    "y_pre_round = []\n",
    "for i in range(len(y_pre)):\n",
    "    y_pre_round.append(1*(y_pre[i] >= thresh))\n",
    "    y_pre_round[i] = y_pre_round[i].tolist()\n",
    "    \n",
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\acer\\Documents\\hoc tap\\khóa luận\\mebe_domain\")\n",
    "from modules.evaluate import cal_aspect_prf\n",
    "\n",
    "X = cal_aspect_prf(y_test_ori_tiki.tolist(), y_pre_round, num_of_aspect=6, verbal=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "436b04a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label = ['ship','giá','chính hãng''','chất lượng','dịch vụ','an toàn']\n",
    "# res = {'label':label,'p':X[0], 'r':X[1], 'f1':X[2]}\n",
    "# df = pd.DataFrame(res)\n",
    "# df1 = pd.DataFrame({'micro':X[3], 'macro': X[4]})\n",
    "# final_df=pd.concat([df,df1], axis=1)\n",
    "\n",
    "# final_df.to_csv(r\"C:\\Users\\acer\\Documents\\hoc tap\\khóa luận\\mebe_domain_pre\\ket qua\\distill lstm 512 concat\\0.7 distill 0.3 train.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f66b9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251c85ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e969c07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c411cdc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9835e1d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87c3b62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f495931",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824caf7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdf26d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59996af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b816aca2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07fbeb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6149c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
