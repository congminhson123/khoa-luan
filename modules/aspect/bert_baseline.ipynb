{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e7943c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:67: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.6.0 and strictly below 2.9.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.3.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  UserWarning,\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "# from models import Input, AspectOutput\n",
    "from tensorflow.keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Conv1D,GRU\n",
    "from tensorflow.keras.layers import Bidirectional, GlobalMaxPool1D, Concatenate\n",
    "from tensorflow.keras.models import Model,load_model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow_addons as tfa\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44e98964",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_bert = np.load(r\"C:\\Users\\acer\\Documents\\hoc tap\\khóa luận\\mebe_domain\\phobert_embed.npy\", allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fdb4e3c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 768)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_bert[4].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32a73a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "567aa45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_bert_padding = []\n",
    "for sen in pre_bert:\n",
    "    emb = np.zeros((max_len, 768))\n",
    "    for i in range(len(sen)):\n",
    "        try:\n",
    "            emb[i] = sen[i]\n",
    "        except: continue\n",
    "    pre_bert_padding.append(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14aab11d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pre_bert_padding[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfe47249",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6004"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pre_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0e1104a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_bert_shopee = np.array(pre_bert_padding[0:3017])\n",
    "pre_bert_tiki = np.array(pre_bert_padding[3017:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30a8e8d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2987"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pre_bert_tiki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7653893c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (\"../../output_shopee.txt\", \"r\") as f:\n",
    "    output_ori_shopee = np.array(json.loads(f.read()))\n",
    "with open (\"../../output_tiki.txt\", \"r\") as f:\n",
    "    output_ori_tiki = np.array(json.loads(f.read()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2dc449b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_shopee, X_test_shopee, y_train_ori_shopee, y_test_ori_shopee = train_test_split(pre_bert_shopee, output_ori_shopee, test_size=0.2, random_state=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd38ed85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2413"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_shopee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e3eb65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_shopee = np.delete(y_train_ori_shopee, 6, 1)\n",
    "y_test_shopee = np.delete(y_test_ori_shopee, 6, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8583d74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = tfa.metrics.F1Score(num_classes=6, average='micro', threshold=0.5)\n",
    "# rlp = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',mode='min', patience=3, verbose=1, factor=0.4)\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss',mode='min', patience=6, verbose=1, restore_best_weights=True)\n",
    "filepath = ('./weights/best_teacher.h5')\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_f1_score', verbose=1, save_best_only=True,save_weights_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41cde5a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 50, 768)]         0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 50, 256)           918528    \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 48, 64)            49216     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 985,926\n",
      "Trainable params: 985,926\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/15\n",
      "302/302 [==============================] - ETA: 0s - loss: 0.4697 - f1_score: 0.5059\n",
      "Epoch 00001: val_f1_score improved from 0.52430 to 0.52616, saving model to ./weights\\best_teacher.h5\n",
      "302/302 [==============================] - 39s 129ms/step - loss: 0.4697 - f1_score: 0.5059 - val_loss: 0.4332 - val_f1_score: 0.5262\n",
      "Epoch 2/15\n",
      "302/302 [==============================] - ETA: 0s - loss: 0.4303 - f1_score: 0.5242\n",
      "Epoch 00002: val_f1_score did not improve from 0.52616\n",
      "302/302 [==============================] - 39s 129ms/step - loss: 0.4303 - f1_score: 0.5242 - val_loss: 0.4508 - val_f1_score: 0.5067\n",
      "Epoch 3/15\n",
      "302/302 [==============================] - ETA: 0s - loss: 0.4026 - f1_score: 0.5906\n",
      "Epoch 00003: val_f1_score improved from 0.52616 to 0.58633, saving model to ./weights\\best_teacher.h5\n",
      "302/302 [==============================] - 41s 137ms/step - loss: 0.4026 - f1_score: 0.5906 - val_loss: 0.4003 - val_f1_score: 0.5863\n",
      "Epoch 4/15\n",
      "302/302 [==============================] - ETA: 0s - loss: 0.3903 - f1_score: 0.6021\n",
      "Epoch 00004: val_f1_score improved from 0.58633 to 0.61808, saving model to ./weights\\best_teacher.h5\n",
      "302/302 [==============================] - 41s 135ms/step - loss: 0.3903 - f1_score: 0.6021 - val_loss: 0.3820 - val_f1_score: 0.6181\n",
      "Epoch 5/15\n",
      "302/302 [==============================] - ETA: 0s - loss: 0.3817 - f1_score: 0.6122\n",
      "Epoch 00005: val_f1_score did not improve from 0.61808\n",
      "302/302 [==============================] - 41s 136ms/step - loss: 0.3817 - f1_score: 0.6122 - val_loss: 0.3833 - val_f1_score: 0.6144\n",
      "Epoch 6/15\n",
      "302/302 [==============================] - ETA: 0s - loss: 0.3760 - f1_score: 0.6178\n",
      "Epoch 00006: val_f1_score improved from 0.61808 to 0.61843, saving model to ./weights\\best_teacher.h5\n",
      "302/302 [==============================] - 41s 135ms/step - loss: 0.3760 - f1_score: 0.6178 - val_loss: 0.3830 - val_f1_score: 0.6184\n",
      "Epoch 7/15\n",
      "302/302 [==============================] - ETA: 0s - loss: 0.3730 - f1_score: 0.6245\n",
      "Epoch 00007: val_f1_score did not improve from 0.61843\n",
      "302/302 [==============================] - 41s 135ms/step - loss: 0.3730 - f1_score: 0.6245 - val_loss: 0.3806 - val_f1_score: 0.6121\n",
      "Epoch 8/15\n",
      "302/302 [==============================] - ETA: 0s - loss: 0.3663 - f1_score: 0.6312\n",
      "Epoch 00008: val_f1_score improved from 0.61843 to 0.66092, saving model to ./weights\\best_teacher.h5\n",
      "302/302 [==============================] - 44s 144ms/step - loss: 0.3663 - f1_score: 0.6312 - val_loss: 0.3688 - val_f1_score: 0.6609\n",
      "Epoch 9/15\n",
      "302/302 [==============================] - ETA: 0s - loss: 0.3674 - f1_score: 0.6371\n",
      "Epoch 00009: val_f1_score did not improve from 0.66092\n",
      "302/302 [==============================] - 41s 135ms/step - loss: 0.3674 - f1_score: 0.6371 - val_loss: 0.3819 - val_f1_score: 0.6160\n",
      "Epoch 10/15\n",
      "302/302 [==============================] - ETA: 0s - loss: 0.3775 - f1_score: 0.6311\n",
      "Epoch 00010: val_f1_score did not improve from 0.66092\n",
      "302/302 [==============================] - 42s 140ms/step - loss: 0.3775 - f1_score: 0.6311 - val_loss: 0.3853 - val_f1_score: 0.6280\n",
      "Epoch 11/15\n",
      "302/302 [==============================] - ETA: 0s - loss: 0.3707 - f1_score: 0.6287\n",
      "Epoch 00011: val_f1_score did not improve from 0.66092\n",
      "302/302 [==============================] - 43s 142ms/step - loss: 0.3707 - f1_score: 0.6287 - val_loss: 0.3848 - val_f1_score: 0.6039\n",
      "Epoch 12/15\n",
      "302/302 [==============================] - ETA: 0s - loss: 0.3618 - f1_score: 0.6410\n",
      "Epoch 00012: val_f1_score did not improve from 0.66092\n",
      "302/302 [==============================] - 41s 137ms/step - loss: 0.3618 - f1_score: 0.6410 - val_loss: 0.3819 - val_f1_score: 0.6288\n",
      "Epoch 13/15\n",
      "302/302 [==============================] - ETA: 0s - loss: 0.3510 - f1_score: 0.6607\n",
      "Epoch 00013: val_f1_score did not improve from 0.66092\n",
      "302/302 [==============================] - 39s 130ms/step - loss: 0.3510 - f1_score: 0.6607 - val_loss: 0.3591 - val_f1_score: 0.6426\n",
      "Epoch 14/15\n",
      "302/302 [==============================] - ETA: 0s - loss: 0.3525 - f1_score: 0.6524\n",
      "Epoch 00014: val_f1_score improved from 0.66092 to 0.66792, saving model to ./weights\\best_teacher.h5\n",
      "302/302 [==============================] - 41s 134ms/step - loss: 0.3525 - f1_score: 0.6524 - val_loss: 0.3651 - val_f1_score: 0.6679\n",
      "Epoch 15/15\n",
      "302/302 [==============================] - ETA: 0s - loss: 0.3488 - f1_score: 0.6681"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1000\\1893138186.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'binary_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mf1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_shopee\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_shopee\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_shopee\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test_shopee\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1131\u001b[0m               \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1133\u001b[1;33m               return_dict=True)\n\u001b[0m\u001b[0;32m   1134\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'val_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mval\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1135\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[0;32m   1377\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'TraceContext'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgraph_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1378\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1379\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1380\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1381\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    812\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 814\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    815\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    816\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[0;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1924\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def get_model():\n",
    "    inp = Input(shape=(max_len, 768))\n",
    "#     x = Embedding(len(embed_mat), feat_vec, weights=[np.array(embed_mat)], input_length=max_len,trainable=True)(inp) # trọng số của từ sẽ không được train lại\n",
    "    x = Bidirectional(LSTM(128, return_sequences=True))(inp)\n",
    "    x = Conv1D(64,3,activation=\"relu\")(x)\n",
    "    x = GlobalMaxPool1D()(x)\n",
    "    x = Dense(256, activation=\"relu\")(x)\n",
    "#     convo1 = Conv1D(64,3,activation=\"relu\")(x)\n",
    "#     convo1_maxpool = GlobalMaxPool1D()(convo1)\n",
    "#     convo2 = Conv1D(128,4,activation=\"relu\")(x)\n",
    "#     convo2_maxpool = GlobalMaxPool1D()(convo2)\n",
    "#     convo3 = Conv1D(64,5,activation=\"relu\")(x)\n",
    "#     convo3_maxpool = GlobalMaxPool1D()(convo3)\n",
    "#     concat1 = Concatenate()([convo1_maxpool, convo2_maxpool])\n",
    "#     concat2 = Concatenate()([concat1, convo3_maxpool])\n",
    "#     x = Dense(256, activation=\"relu\")(concat2)\n",
    "    \n",
    "    x = Dense(6, activation=\"sigmoid\")(x)\n",
    "    model = Model(inputs=inp, outputs=x)\n",
    "    print(model.summary())\n",
    "\n",
    "    return model\n",
    "    \n",
    "# model = get_model(X_train, X_test, y_train, y_test)\n",
    "# model = get_model(padded_doc_shopee, X_test_tiki, output_train_shopee, y_test_tiki)\n",
    "model = get_model()\n",
    "model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(lr=0.01), metrics= [f1])\n",
    "model.fit(X_train_shopee, y_train_shopee, batch_size=8, epochs=15, validation_data=(X_test_shopee, y_test_shopee), callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "309f99b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 50, 768)]         0         \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 50, 256)           918528    \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 48, 64)            49216     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 985,926\n",
      "Trainable params: 985,926\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "new_model = get_model()\n",
    "new_model.load_weights('./weights/best_teacher.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "040902bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "def evaluate(X_test, y_test, model):    \n",
    "    y_pre = model.predict(X_test)\n",
    "    for thresh in np.arange(0.2,0.7,0.01):\n",
    "        print(\"threshold {0:2.2f} f1 score:{1:2.3f}\".format(thresh,metrics.f1_score(y_test,(y_pre>thresh).astype(int), average='micro')))\n",
    "    return y_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6c0ab0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold 0.20 f1 score:0.624\n",
      "threshold 0.21 f1 score:0.630\n",
      "threshold 0.22 f1 score:0.639\n",
      "threshold 0.23 f1 score:0.644\n",
      "threshold 0.24 f1 score:0.652\n",
      "threshold 0.25 f1 score:0.659\n",
      "threshold 0.26 f1 score:0.661\n",
      "threshold 0.27 f1 score:0.666\n",
      "threshold 0.28 f1 score:0.667\n",
      "threshold 0.29 f1 score:0.675\n",
      "threshold 0.30 f1 score:0.679\n",
      "threshold 0.31 f1 score:0.683\n",
      "threshold 0.32 f1 score:0.686\n",
      "threshold 0.33 f1 score:0.682\n",
      "threshold 0.34 f1 score:0.680\n",
      "threshold 0.35 f1 score:0.685\n",
      "threshold 0.36 f1 score:0.689\n",
      "threshold 0.37 f1 score:0.686\n",
      "threshold 0.38 f1 score:0.686\n",
      "threshold 0.39 f1 score:0.686\n",
      "threshold 0.40 f1 score:0.685\n",
      "threshold 0.41 f1 score:0.683\n",
      "threshold 0.42 f1 score:0.684\n",
      "threshold 0.43 f1 score:0.683\n",
      "threshold 0.44 f1 score:0.684\n",
      "threshold 0.45 f1 score:0.682\n",
      "threshold 0.46 f1 score:0.684\n",
      "threshold 0.47 f1 score:0.677\n",
      "threshold 0.48 f1 score:0.677\n",
      "threshold 0.49 f1 score:0.669\n",
      "threshold 0.50 f1 score:0.668\n",
      "threshold 0.51 f1 score:0.648\n",
      "threshold 0.52 f1 score:0.644\n",
      "threshold 0.53 f1 score:0.639\n",
      "threshold 0.54 f1 score:0.631\n",
      "threshold 0.55 f1 score:0.629\n",
      "threshold 0.56 f1 score:0.623\n",
      "threshold 0.57 f1 score:0.619\n",
      "threshold 0.58 f1 score:0.619\n",
      "threshold 0.59 f1 score:0.618\n",
      "threshold 0.60 f1 score:0.618\n",
      "threshold 0.61 f1 score:0.618\n",
      "threshold 0.62 f1 score:0.618\n",
      "threshold 0.63 f1 score:0.617\n",
      "threshold 0.64 f1 score:0.617\n",
      "threshold 0.65 f1 score:0.617\n",
      "threshold 0.66 f1 score:0.615\n",
      "threshold 0.67 f1 score:0.615\n",
      "threshold 0.68 f1 score:0.616\n",
      "threshold 0.69 f1 score:0.614\n"
     ]
    }
   ],
   "source": [
    "y_pre=evaluate(X_test_shopee, y_test_shopee, new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "01497e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh=0.36\n",
    "y_pre_round = []\n",
    "for i in range(len(y_pre)):\n",
    "    y_pre_round.append(1*(y_pre[i] >= thresh))\n",
    "    y_pre_round[i] = y_pre_round[i].tolist()\n",
    "    if 1 not in y_pre_round[i]:\n",
    "        y_pre_round[i].append(1)\n",
    "    else: y_pre_round[i].append(0)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "da902b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p: [0.9487179487179487, 0.9108910891089109, 0, 0.48338368580060426, 0, 0, 0.2727272727272727]\n",
      "r: [0.9319899244332494, 0.8932038834951457, 0, 0.7174887892376681, 0, 0, 0.5094339622641509]\n",
      "f1: [0.940279542566709, 0.9019607843137256, 0, 0.5776173285198556, 0, 0, 0.3552631578947368]\n",
      "micro: (0.7566909975669099, 0.6327568667344863, 0.689196675900277)\n",
      "macro: (0.390498787271244, 0.42378043286101047, 0.40330960923338166)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\acer\\Documents\\hoc tap\\khóa luận\\mebe_domain\")\n",
    "from modules.evaluate import cal_aspect_prf\n",
    "\n",
    "X = cal_aspect_prf(y_test_ori_shopee.tolist(), y_pre_round, num_of_aspect=7, verbal=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b3dcffc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label = ['ship','giá','chính hãng''','chất lượng','dịch vụ','an toàn','others']\n",
    "# res = {'label':label,'p':X[0], 'r':X[1], 'f1':X[2]}\n",
    "# df = pd.DataFrame(res)\n",
    "# df1 = pd.DataFrame({'micro':X[3], 'macro': X[4]})\n",
    "# final_df=pd.concat([df,df1], axis=1)\n",
    "\n",
    "# final_df.to_csv(r\"C:\\Users\\acer\\Documents\\hoc tap\\khóa luận\\mebe_domain\\ket qua\\bert_baseline.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2621286d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
